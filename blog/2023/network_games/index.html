<!DOCTYPE html> <html> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Learning Network Games | Emanuele Rossi </title> <meta name="author" content="Emanuele Rossi"> <meta name="description" content="Network games are a powerful tool for modelling strategic interactions between individuals or organisations played out on networks, where a player's payoff depends not only on their own actions but also on those of their neighbours. Such games have numerous applications in economics and social sciences, including studying the spread of influence in social networks, the dynamics of financial markets, and the formation of alliances in international relations. The study of network games typically assumes the underlying network structure to be known, which is often wishful thinking. Recently, machine learning approaches have been proposed to tackle this problem by leveraging the observed actions of players to learn the underlying network structure. In this blog post, we outline a novel approach that uses a transformer-like architecture to infer the network structure of a game without explicit knowledge of the utility function associated with the game."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <meta http-equiv="Content-Security-Policy" content="default-src 'self'; script-src 'self' 'unsafe-inline' https:; style-src 'self' 'unsafe-inline' https:; img-src 'self' data: https:; font-src 'self' data: https:; media-src 'self' https:; frame-src 'self' https:; connect-src 'self' https:;"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?v=16404ec2cd2689e8d0f38f73fe0d38f9"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?v=f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?v=62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?v=591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/dolphin.png?v=0682a379aac8fb601c63d389d444b582"> <link rel="stylesheet" href="/assets/css/main.css?v=d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://emalgorithm.github.io/blog/2023/network_games/"> <script src="/assets/js/theme.js?v=5fea5159b787642c1bbc1f334d60f883"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?v=5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> <script src="/assets/js/distillpub/template.v2.js"></script> <script src="/assets/js/distillpub/transforms.v2.js"></script> </head> <body> <d-front-matter> <script async type="text/json">
      {
            "title": "Learning Network Games",
            "description": "Network games are a powerful tool for modelling strategic interactions between individuals or organisations played out on networks, where a player's payoff depends not only on their own actions but also on those of their neighbours. Such games have numerous applications in economics and social sciences, including studying the spread of influence in social networks, the dynamics of financial markets, and the formation of alliances in international relations. The study of network games typically assumes the underlying network structure to be known, which is often wishful thinking. Recently, machine learning approaches have been proposed to tackle this problem by leveraging the observed actions of players to learn the underlying network structure. In this blog post, we outline a novel approach that uses a transformer-like architecture to infer the network structure of a game without explicit knowledge of the utility function associated with the game.",
            "published": "April 20, 2023",
            "authors": [
              
              {
                "author": "Emanuele Rossi",
                "authorURL": "www.emanuelerossi.co.uk",
                "affiliations": [
                  {
                    "name": "Imperial College London",
                    "url": ""
                  }
                ]
              },
              
              {
                "author": "Michael Bronstein",
                "authorURL": "https://en.wikipedia.org/wiki/Michael_Bronstein",
                "affiliations": [
                  {
                    "name": "University of Oxford",
                    "url": ""
                  }
                ]
              }
              
            ],
            "katex": {
              "delimiters": [
                {
                  "left": "$",
                  "right": "$",
                  "display": false
                },
                {
                  "left": "$$",
                  "right": "$$",
                  "display": true
                }
              ]
            }
          }
    </script> </d-front-matter> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Emanuele</span> Rossi </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/outreach/">Outreach </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="fa-solid fa-magnifying-glass"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-half-sun-moon" id="light-toggle-system"></i> <i class="fa-solid fa-moon" id="light-toggle-dark"></i> <i class="fa-solid fa-sun" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="post distill"> <d-title> <h1>Learning Network Games</h1> <p>Network games are a powerful tool for modelling strategic interactions between individuals or organisations played out on networks, where a player's payoff depends not only on their own actions but also on those of their neighbours. Such games have numerous applications in economics and social sciences, including studying the spread of influence in social networks, the dynamics of financial markets, and the formation of alliances in international relations. The study of network games typically assumes the underlying network structure to be known, which is often wishful thinking. Recently, machine learning approaches have been proposed to tackle this problem by leveraging the observed actions of players to learn the underlying network structure. In this blog post, we outline a novel approach that uses a transformer-like architecture to infer the network structure of a game without explicit knowledge of the utility function associated with the game.</p> </d-title> <d-byline></d-byline> <d-article> <d-contents> <nav class="l-text figcaption"> <h3>Contents</h3> <div> <a href="#network-games">Network Games</a> </div> <div> <a href="#inferring-the-network-from-the-actions">Inferring the Network from the Actions</a> </div> <div> <a href="#machine-learning-approach">Machine Learning Approach</a> </div> <div> <a href="#experimental-results">Experimental Results</a> </div> </nav> </d-contents> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/network_games/cover-480.webp 480w,/assets/img/blog/network_games/cover-800.webp 800w,/assets/img/blog/network_games/cover-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/blog/network_games/cover.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Illustration based on Shutterstock.</figcaption> </figure> <p><em>This post is based on the paper <a href="https://arxiv.org/abs/2206.08119" rel="external nofollow noopener" target="_blank">Learning to infer the structure of network games</a><d-cite key="rossi2022networkgames"></d-cite>, a collaboration with <a href="https://scholar.google.it/citations?user=NUdNFucAAAAJ&amp;hl=it" rel="external nofollow noopener" target="_blank">Federico Monti</a>, <a href="https://yleng.github.io/www/" rel="external nofollow noopener" target="_blank">Yan Leng</a>, and <a href="https://eng.ox.ac.uk/people/xiaowen-dong/" rel="external nofollow noopener" target="_blank">Xiaowen Dong</a>. The same blog post has been also published on <a href="https://medium.com/data-science/learning-network-games-29970aee44bb" rel="external nofollow noopener" target="_blank">Medium</a>.</em></p> <h2 id="network-games">Network Games</h2> <p><a href="https://en.wikipedia.org/wiki/Game_theory" rel="external nofollow noopener" target="_blank">Game theory</a> is a mathematical framework for modelling and analysing situations where multiple decision makers interact with each other, and where the outcome of each decision depends on the actions of all players involved. In <em>network games</em><d-footnote>See <a href="https://web.stanford.edu/~jacksonm/GamesNetworks.pdf" rel="external nofollow noopener" target="_blank">Games on Networks</a><d-cite key="jackson2014games"></d-cite> for an overview.</d-footnote> the players are connected in a network (graph), and the outcome of the game depends not only on the players’ strategies but also on the structure of the network. Each player tries to maximise their <em>utility function</em>, which in the case of network games depends both on their own actions and the actions of their neighbours.</p> <p><em>Equilibrium actions</em> refer to a set of strategies where no player has an incentive to change their strategy, given the strategies of the other players. In other words, at equilibrium, each player’s strategy is optimal, given the strategies of the other players. In network games, the equilibrium actions depend on the graph structure, along with other parameters dependent on the game.</p> <p>Consider, for example, a scenario where individuals on a social network can decide how much time to spend on the platform. In such a case, their behaviours may be influenced by their friends on the network, which creates a strategic interdependence between players. For instance, if Joe’s friends spend a lot of time on the platform, Joe might perceive a greater benefit from using the platform himself.</p> <p>In a different setting, Joe is a user of an e-commerce platform deciding whether to buy a book. If his friend has already purchased the book, Joe might be less likely to buy it, as he can borrow it from his friend. These examples illustrate how actions in network games can be affected by the actions of neighbouring players, leading to strategic interdependence and the emergence of equilibrium actions.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/network_games/network_games_examples-480.webp 480w,/assets/img/blog/network_games/network_games_examples-800.webp 800w,/assets/img/blog/network_games/network_games_examples-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/blog/network_games/network_games_examples.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Examples of network games. Left: a person is likely to spend more time on a social app if their friends are also spending time on the app. Right: a person has less incentive to buy a book if their friend bought it, because they can borrow it.</figcaption> </figure> <h2 id="inferring-the-network-from-the-actions">Inferring the Network from the Actions</h2> <p>In the above examples, we assumed to know the friends of Joe, i.e., the network structure of the game. However, in many situations, the underlying network structure is not directly available to us. Instead, we may only observe the equilibrium actions that result from the interactions between agents. In these cases, a crucial question is whether we can reconstruct the network structure based solely on these equilibrium actions. Knowing the network structure can be helpful in predicting behaviour and planning network-based interventions, such as marketing campaigns or information diffusion.</p> <p>It was previously shown that, under specific assumptions about the mathematical form of the utility function and game types, it is possible to reconstruct the graph governing the network game<d-cite key="leng2020learning"></d-cite>. However, such assumptions can be unrealistic, especially when little is known about the game being played. To address this, in a recent paper<d-cite key="rossi2022networkgames"></d-cite> we developed an approach that does not require assumptions about the form of the utility function and can be applied to a broad range of network games.</p> <p>We start by studying three common types of network games, <em>Linear Quadratic</em>, <em>Linear Influence</em>, and <em>Barik-Honorio</em><d-cite key="barik2020provable"></d-cite>. The three types of games differ by the form of the utility function, leading to different levels of smoothness of the actions in the graph.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/network_games/network_games_types-480.webp 480w,/assets/img/blog/network_games/network_games_types-800.webp 800w,/assets/img/blog/network_games/network_games_types-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/blog/network_games/network_games_types.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Specific instances of three different types of games common in the game theory literature. The colours represent the actions taken by the players, which in this case are continuous values normalised between -1 and 1.</figcaption> </figure> <p>For example, <em>Linear Quadratic</em> games have the following utility function:</p> \[u_i = b_i x_i -\frac{1}{2} x_i^2 + \beta \sum_{j \in \mathcal{N}_i} a_{ij} x_i x_j\] <p>where \(x_i\) is the continuous action taken by player $i$, \(b_i\) is the player’s <em>marginal benefit</em>, \(\beta\) is a game parameter representing the strength of dependencies between actions of neighbours in the network, and \(a_{ij}\) is the entry in the adjacency matrix of the graph representing the strength of the connection between \(i\) and \(j\). The first term represents the marginal benefit for taking a larger action, the second (quadratic) term represents the cost for taking the action, while the third term represents the relation with the neighbours actions<d-footnote>If $\beta$ is positive, the incentive of a player to take a higher action is increasing in the number of their neighbours also taking a higher action, something referred to as a <i>strategic complement relationship</i>. On the other hand, if $\beta$ is negative the incentive of a player to take a higher action is decreasing in the number of their neighbours taking a higher action (<i>strategic substitute relationship</i>).</d-footnote>. Taking as example the aforementioned scenario of time spent on a social platform, the first term of the equation would capture the individual benefit from using the platform, such as staying up-to-date with the news, the second term would represent the cost from doing so, such as having less time to do other more important things, while the third term would capture the interdependence with the friends actions. In particular, \(\beta\) would be positive, as a person has an incentive to spend more time on the app if their friends (neighbours) do so.</p> <p>The pure-strategy <a href="https://en.wikipedia.org/wiki/Nash_equilibrium" rel="external nofollow noopener" target="_blank">Nash equilibrium</a> of <em>Linear Quadratic</em> games is:</p> \[\mathbf{x}^* = \big( \mathbf{I} - \beta \mathbf{A} \big)^{-1} \mathbf{b}\] <p>where \(\mathbf{x}\)* is a vector of dimension \(n\) (equal to the number of players, or nodes of the graph), \(\mathbf{A}\) is the unknown \(n \times n\) adjacency matrix of the graph, \(\mathbf{b}\) is the \(n\)-dimensional vector of marginal benefits of the players.</p> <p>Similar formulas can be derived for <em>Linear Influence</em> and <em>Barik-Honorio</em> games. A formula for the equilibrium actions \(\mathbf{x}^*\) that generalizes all three games has the form<d-footnote>In this formula, the choice $f(\mathbf{A})=(\mathbf{I} - \beta\mathbf{A})^{-1}$ and $h(\mathbf{b})=\mathbf{b}$ yields a Linear Quadratic game, $f(\mathbf{A})=\mathbf{A}^{-1}$ and $h(\mathbf{b})=\mathbf{b}$ a Linear Influence game, and $f(\mathbf{A})=\mathbf{u}_1$ (the largest eigenvector of $\mathbf{A}$) and $h(\mathbf{b})=1$ a game of the Barik-Honorio type. </d-footnote></p> \[\mathbf{x}^* = \mathcal{F} (\mathbf{A}) \mathcal{H} (\mathbf{b})\] <p>where the function \(\mathcal{F} (\mathbf{A})\) accounts for the influence from the actions of one’s neighbours in the network and encodes the specific utility function of the game, and conversely, \(\mathcal{H} (\mathbf{b})\) is only affected by one’s characteristics, such as the marginal benefit of an individual player.</p> <p>In the paper we further show<d-footnote>Section 3.3 in our paper<d-cite key="rossi2022networkgames"></d-cite>.</d-footnote> that the players’ actions contain information about the spectrum of the graph, confirming that it is possible to reconstruct the graph structure from only the actions and justifying our approach outlined below.</p> <h2 id="machine-learning-approach">Machine Learning Approach</h2> <p>To tackle the problem of inferring the network structure of a game, we approach it as a machine learning problem. We train a model to map the players’ actions to the network structure of the game, without any prior knowledge of the underlying utility function. To achieve this, we gather a dataset of actions and network pairs (\(\mathbf{x}\), \(\mathbf{A}\)) from games played with the same utility function (although this function is unknown to us). This allows us to avoid making strong assumptions about the utility function and instead train a model that is agnostic to it.</p> <p>Such an approach is particularly useful in scenarios where social network and decision data exist for a small population, and we aim to learn the mapping from decisions to the network structure of a larger population. For instance, governments, public agencies, and researchers can collect social network data on a small population by asking individuals to nominate their friends, and then use the proposed method to learn the network interactions for a larger population in a cost-effective manner.</p> <p>Our ML model has an encoder-decoder architecture that is invariant to the permutation of both the players and the games, corresponding to the rows and columns of the \(n \times K\) matrix \(\mathbf{x}\), where \(k\) denotes the number of games. To achieve this, we modify a Transformer model, which is naturally permutation-invariant over the set of nodes but not over the set of games.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/network_games/model.svg" sizes="95vw"></source> <img src="/assets/img/blog/network_games/model.svg" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">Diagram representing the encoder-decoder architecture of our model. The $n \\times K$ input matrix $\\mathbf{x}$ containing the players' actions is encoded into the $n \\times F \\times K$ tensor $\\mathbf{Z}$, where $\\mathbf{z}_{ik}$ is the embedding for node $i$ in game $k$, obtained by attending over the actions of the other players in the same game. $\\mathbf{Z}$ is then decoded into the $n \\times n$ adjacency matrix $\\tilde{\\mathbf{A}}$ where the entry $\\tilde{\\mathbf{a}}_{ij}$ contains the probability of an edge between $i$ and $j$.</figcaption> </figure> <p>Our encoder produces \(K\) vectors for each player as follows:</p> <p>The scalar action \(\mathbf{x}_{ik}\) of player \(i\) for game \(k\) is first passed through a non-linear transformation resulting in an \(F\)-dimensional vector</p> \[\mathbf{y}_{ik} = \text{ReLU}(\mathbf{x}_{ik}\mathbf{W} + \mathbf{b})\] <p>We then calculate the unnormalised attention scores</p> \[s_{ij} = \sum_{k} \mathbf{y}_{ik}^T \mathbf{W} \mathbf{W}_k \mathbf{y}_{jk}\] <p>between players \(i\) and \(j\) by first computing per-game scores using a ‘learned dot-product’ with query and key weight matrices \(\mathbf{W}\) and \(\mathbf{W}_k\) as in the original Transformer<d-footnote>See "<a href="https://jalammar.github.io/illustrated-transformer/" rel="external nofollow noopener" target="_blank">The Illustrated Transformer</a>" blog post for an intuitive explanation of the Transformer and the role of the query and weight matrices.</d-footnote>, and then summing them over the games.</p> <p>The attention scores</p> \[\alpha_{ij} = \text{softmax}_{j}(u_{ij})\] <p>are obtained by taking the softmax over the unnormalised scores over the second dimension.</p> <p>Finally, the \(F\)-dimension embedding</p> \[\mathbf{z}_{ik} = \phi\left(\sum_{v} \alpha_{ij}\mathbf{y}_{jk}\right)\] <p>of node \(i\) for game \(k\) is obtained by aggregating the \(\mathbf{y}_{ik}\) vectors of other nodes weighted by the attention scores, before passing the result through a 2-layer MLP \(\phi\).</p> <p>The decoder outputs probabilities for each entry of the adjacency matrix by aggregating the \(k\) vectors for players \(i\) and \(j\). This is done by taking the dot product of the two vectors for each game and summing the results before feeding them into a multilayer perceptron (MLP):</p> \[\hat{a}_{ij} = \psi\left(\sum_{k} \mathbf{z}_{ik} \odot \mathbf{Z}_{jk}\right)\] <p>where \(\odot\) represents the dot product and \(\psi\) is a 2-layer MLP.</p> <p>The resulting model is permutation-invariant over the set of games. This means that it produces the same predicted adjacency matrix regardless of the order in which the games are presented. To achieve this, the model computes separate node embeddings for each game and aggregates them through summation, which is a permutation-invariant operation. In practice, this property of the model ensures that we obtain consistent and reliable predictions, regardless of how the input data is ordered.</p> <h2 id="experimental-results">Experimental Results</h2> <p>We conducted experiments to validate the effectiveness of our approach in learning the network structure from players’ actions, using both synthetic and real-world datasets. As baselines, we used DeepGraph<d-cite key="belilovsky2017learning"></d-cite> (the only machine learning approach we are aware of), optimisation methods specific to the game type, and simple correlation and anticorrelation of actions between nodes.</p> <p>On synthetic datasets, our model, NuGgeT, consistently outperformed previous methods across a range of different games and graphs types.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/network_games/linear_quadratic_results-480.webp 480w,/assets/img/blog/network_games/linear_quadratic_results-800.webp 800w,/assets/img/blog/network_games/linear_quadratic_results-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/blog/network_games/linear_quadratic_results.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">We report the results on <em>Linear Influence</em> games (see the paper for <em>Linear Quadratic</em> and <em>Barik-Honorio</em>) on three different types of synthetic graphs (Watts–Strogatz, Erdős–Rényi and Barabási–Albert) and with varying smoothness of the marginal benefit (a hyperparameter of this type of game). Our method, called NuGgeT, consistently outperforms the baselines.</figcaption> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/network_games/ablation-480.webp 480w,/assets/img/blog/network_games/ablation-800.webp 800w,/assets/img/blog/network_games/ablation-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/blog/network_games/ablation.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">The performance of our model in learning the mapping depends on the number of available games and training graphs, and we conducted ablations to evaluate both factors. Generally, a higher number of games and graphs are beneficial for our approach. However, we observe that the model performance tends to plateau at around 100 games and 500 graphs in most cases.</figcaption> </figure> <p>We further validated our approach on two real-world datasets: the <em>Indian Villages</em> dataset<d-footnote>The dataset accompanies the paper <a href="https://www.science.org/doi/10.1126/science.1236498" rel="external nofollow noopener" target="_blank">"The Diffusion of Microfinance"</a> <d-cite key="banerjee2013diffusion"></d-cite>. Two authors of the paper (Abhijit Banerjee and Esther Duflo) went on to receive the 2019 Economics Nobel prize.</d-footnote> and the <em>Yelp Ratings</em> dataset<d-footnote><a href="https://business.yelp.com/data/resources/open-dataset/" rel="external nofollow noopener" target="_blank">Yelp Open dataset</a>.</d-footnote>. The former contains data from a survey of social networks in 75 villages in India. Each village constitutes a social network graph, where nodes are households and edges are self-reported friendships. We consider as actions the number of rooms, number of beds and other decisions families have to make related to their household. The reasoning is that if neighbours adopt a specific facility, villagers tend to gain higher payoff by doing the same, i.e., complying with social norms.</p> <p>The <em>Yelp Ratings</em> dataset consists of user ratings of businesses and social connectivity between users. We extracted 5000 sub-graphs representing communities from the raw data, where the actions were the average rating of users for 22 categories of businesses.</p> <p>On both real-world datasets, NuGgeT outperforms previous methods, showcasing the efficacy of our approach in cases where the game utility is not explicitly known. The gain is particularly large on the <em>Indian Villages</em> dataset, where the competing DeepGraph method fails to learn altogether. We conjecture this is due to NuGgeT being more data-efficient thanks to its built-in invariances, as confirmed by the above ablation over the number of training graphs.</p> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/network_games/table_results-480.webp 480w,/assets/img/blog/network_games/table_results-800.webp 800w,/assets/img/blog/network_games/table_results-1400.webp 1400w," type="image/webp" sizes="95vw"></source> <img src="/assets/img/blog/network_games/table_results.png" class="img-fluid" width="500px" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> <figcaption class="caption">The table reports ROC AUC on the test set. NuGgeT outperforms previous methods on both the two real-world datasets we tested on, confirming its efficacy in cases where the game utility function is not explicitly known.</figcaption> </figure> <p>In conclusion, our paper highlights the fruitful connection between game theory and graph machine learning, particularly in the context of network games. By developing a new machine learning approach to infer network structure from observed game outcomes, we show the potential for utilising game theory ideas to enhance machine learning and vice versa. Looking forward, there is ample opportunity to explore further connections between network games and graph neural networks, paving the way for more exciting developments in these fields.</p> </d-article> <d-appendix> <d-footnote-list></d-footnote-list> <d-citation-list></d-citation-list> </d-appendix> <d-bibliography src="/assets/bibliography/2023-04-20-network_games.bib"></d-bibliography> <d-article> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://www.graphcore.ai/posts/accelerating-and-scaling-temporal-graph-networks-on-the-graphcore-ipu" target="_blank" rel="external nofollow noopener">Accelerating and scaling temporal graph networks on the Graphcore IPU</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/data-science/simple-scalable-graph-neural-networks-7eb04f366d07" target="_blank" rel="external nofollow noopener">Just a moment...</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://blog.x.com/engineering/en_us/topics/insights/2022/graph-machine-learning-with-missing-node-features" target="_blank" rel="external nofollow noopener">Just a moment...</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://blog.x.com/engineering/en_us/topics/insights/2021/temporal-graph-networks" target="_blank" rel="external nofollow noopener">Just a moment...</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://towardsdatascience.com/temporal-graph-learning-in-2024-feaa9371b8e2/" target="_blank" rel="external nofollow noopener">Temporal Graph Learning in 2024 | Towards Data Science</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <br> <br> </d-article> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Emanuele Rossi. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script src="/assets/js/distillpub/overrides.js"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?v=85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?v=2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?v=c15de51d4bb57887caa2c21988d97279"></script> <script defer src="/assets/js/copy_code.js?v=c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?v=d9f17b6adc2311cbabd747f4538bb15f"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?v=a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?v=2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?v=eaf77346e117baa09987a278a117b9a7"></script> <script>
    addBackToTop();
  </script> <script type="module" src="/assets/js/search/ninja-keys.min.js?v=f8abf2f636f242d077f24149a0a56c96"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script src="/assets/js/search-setup.js?v=6c304f7b1992d4b60f7a07956e52f04a"></script> <script src="/assets/js/search-data.js"></script> <script src="/assets/js/shortcut-key.js?v=ccc841c459bfc0e64c1c2b5acd10df02"></script> </body> </html>